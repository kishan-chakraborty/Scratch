{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init_(self, predicted_class, depth=None):\n",
    "        self.predicted_class = predicted_class  # The majority class\n",
    "        self.feature_index = None               # Feature index of the split.\n",
    "        self.threshold = None                   # The threshold value of the split.\n",
    "        self.depth = None                       # Current depth of the node.\n",
    "        self.n_sample = None                    # No. of sample in the associated data\n",
    "        self.sample_idx = None                  # Indices of samples that belongs to the node.\n",
    "        self.entropy = None                     # Entropy of the sample which belongs to the node.\n",
    "\n",
    "        # If the node has a child node.\n",
    "        self.left = None    # The left child node.\n",
    "        self.right = None   # The right child node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, min_sample_split=2, max_depth=5):\n",
    "        \"\"\"\n",
    "            min_sample_spilt: Min no. of samples required to produce a split.\n",
    "            max_depth: Maximum allowed depth.\n",
    "        \"\"\"\n",
    "        self.min_sample_spilt = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None    # The root node.\n",
    "        self.x_train = None # The training predictor variables.\n",
    "        self.y_train = None # The training response variables.\n",
    "        self.n_sample = None# No. of training samples.\n",
    "        self.n_feat = None  # Feature dimension.\n",
    "\n",
    "    def fit(self, x_train:np.array, y_train:np.array):\n",
    "        \"\"\"\n",
    "            x_train: The predictor values for training.\n",
    "            y_train: The response values corresponding to the training samples.        \n",
    "        \"\"\"\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.n_sample, self.n_feat = self.x_train.shape\n",
    "        self.tree = self._create_root_node()\n",
    "        self.build_tree(self.tree)\n",
    "\n",
    "    def _create_root_node(self) -> Node:\n",
    "        # The class with highest frequency of training samples.\n",
    "        max_class = self.find_most_freq_class(self.y_train)\n",
    "        root_node = Node(max_class)\n",
    "        root_node.n_sample = self.n_sample\n",
    "        root_node.depth = 0\n",
    "        root_node.entropy = self.find_entropy(self.y_train)\n",
    "        root_node.sample_idx = np.array(np.range(self.n_sample))\n",
    "        return root_node\n",
    "    \n",
    "    def find_entropy(self, y: np.array) -> float:\n",
    "        \"\"\"\n",
    "            Calculate entropy of the system.\n",
    "\n",
    "            input\n",
    "                y: response variable\n",
    "\n",
    "            output:\n",
    "                Entropy of the system\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        n_sample = len(y)\n",
    "        count_frac = counts / n_sample\n",
    "        count_frac_log = np.log(count_frac)\n",
    "        out = -1 * (count_frac * count_frac_log).sum()\n",
    "        return out\n",
    "\n",
    "    def find_most_freq_class(self, y: np.array) -> int:\n",
    "        \"\"\"\n",
    "            Class with most frequent sample\n",
    "        \"\"\"\n",
    "        elements, counts = np.unique(y, return_counts=True)\n",
    "        highest_count = counts.argmax()\n",
    "        out = elements[highest_count]\n",
    "        return out\n",
    "\n",
    "\n",
    "    def get_spilt(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def _get_split_info(self, feature_idx, thr, sample_idx):\n",
    "        left_idx = self.x_train[self.x_train[sample_idx, feature_idx] < thr]\n",
    "        right_idx = self.x_train[self.x_train[sample_idx, feature_idx] > thr]\n",
    "\n",
    "        y_left = self.x_train[left_idx], self.y_train[left_idx]\n",
    "        y_right = self.x_train[right_idx], self.y_train[right_idx]\n",
    "\n",
    "        left_entropy = self.find_entropy(y_left)\n",
    "        right_entropy = self.find_entropy(y_right)\n",
    "\n",
    "        out = (len(y_left)/len(sample_idx)) * left_entropy + (len(y_right)/len(sample_idx)) * right_entropy\n",
    "        return out\n",
    "\n",
    "    def get_best_split(self, node:Node) -> tuple[Node, Node]:\n",
    "        \"\"\"\n",
    "            For a given data find the best split based on information gain.\n",
    "\n",
    "            return\n",
    "            LHS subtree [Node]\n",
    "            RHS subtree [Node]\n",
    "        \"\"\"\n",
    "        best_gain = -np.infty\n",
    "        for feature_idx in range(self.n_feat):\n",
    "            feature_vals = self.x_train[node.sample_idx, feature_idx]\n",
    "            potential_thrs = np.unique(feature_vals)\n",
    "\n",
    "            for thr in potential_thrs:\n",
    "                split_info = self._get_split_info(feature_idx, thr, node.sample_idx)\n",
    "                information_gain = node.entropy - split_info\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def build_tree(self, node: Node):\n",
    "        \"\"\"\n",
    "            Recursively build the decision tree by splitting the training data based on certain criteria.\n",
    "        \"\"\"\n",
    "        if node.n_sample > self.min_sample_spilt and node.depth <= self.max_depth:\n",
    "            left_tree, right_tree = self.get_best_split(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
